# 美团全链路压测

## 1 背景

独立压测方式

1 对线上的单机或集群发起服务调用。

2 将线上流量进行录制，然后在单台机器上进行回放。

3 通过修改权重的方式进行引流压测。

缺点：

很难全面的对整个服务集群进行压测

只关注涉及的核心服务，无法覆盖到所有的环节。

系统之间都是通过一些基础服务进行串联，如 Nginx、Redis 缓存、数据库、磁盘、网络等等，而基础服务问题在单服务压测中往往不能被暴露出来。



## 2 美团解决方案  Quake （雷神之锤）压测平台 

1、提供模拟线上真实流量的能力

2、具备快速创建压测环境的能力

3、支持多种压测类型   压测类型除了支持标准的 HTTP 协议， RPC 和移动端协议进行支持。

4、提供压测过程的实时监控与过载保护，具备精准调控 QPS 的能力，秒级监控的能力，预设熔断降级的能力，以及快速定位问题的能力。



### 2.1 Quake 整体架构设计

 Quake 包含数据构造、压测隔离、场景管理、动态调控、过程监控、压测报告为一体等。 具备分布式压测能力的全链路压测系统，通过模拟海量用户真实的业务操作场景。

![1604374529398](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604374529398.png)



Quake-Web：压测管理端，负责压测数据构造、压测环境准备、场景管理、压测过程的动态调整以及压测报表展示等。
Quake-Brain：调度中心，负责施压资源的调度、任务分发与机器资源管理。
Quake-Agent：压测引擎，负责模拟各种压测流量。
Quake-Monitor：监控模块，统计压测结果，监控服务各项指标。



### 2.2 管理端 Quake-Web 

#### 2.2.1 数据构造	 	

##### HTTP 服务的访问日志收集

 在 Nginx 层都会产生请求的访问日志，我们对这些日志进行了统一接入，变成符合压测需要的流量数据。架构图如下： 

![1604374999855](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604374999855.png)

 **词表（请求表）：压测所需的元数据，每一行代表一个请求，包含请求的 method、path、params、header、body等等。** 



##### RPC 线上流量实时录制

对线上服务进行实时流量录制 ，集群中的某几台机器开启录制，根据要录制的接口和方法名，将请求数据上报到录制流量的缓冲服务（Broker）中，再由 Broker 生成最终的请求表，上传到存储平台（S3）。 

![1604375258094](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604375258094.png)

##### 流量参数偏移

有些场景下，构造出来的流量是不能直接使用的，我们需要对用户 ID、手机号等信息进行数据偏移。Quake 也是提供了包含四则运算、区间限定、随机数、时间类型等多种替换规则。

##### 词表文件的分片

数据构造产生的词表文件，我们需要进行物理上的分片，以保证每个分片文件大小尽可能均匀，并且控制在一定大小之内，有助于任务调度更合理的进行分配。

#### 2.2.2 压测隔离

 线上压测要保证压测行为安全且可控，不会影响用户的正常使用，并且不会对线上环境造成任何的数据污染。 

##### 2.2.2.1 测试标识透传

对于单服务来说，识别压测流量很容易，只要在请求头中加个特殊的压测标识即可，HTTP 和 RPC 服务是一样的。但是，要在整条完整的调用链路中要始终保持压测标识，这件事就非常困难。

**跨线程间的透传**

 主线程根据压测请求，将测试标识写入当前线程的 ThreadLocal 对象中（**ThreadLocal 会为每个线程创建一个副本，用来保存线程自身的副本变量**） 

 而对于采用线程池的情况，同样对线程池进行了封装，在往线程池中添加线程任务时，额外保存了 ThreadLocal 中的变量 

**跨服务间的透传**

对于跨服务的调用，架构团队对所有涉及到的中间件进行了一一改造。利用 Mtrace （**公司内部统一的分布式会话跟踪系统**）的服务间传递上下文特性，在原有传输上下文的基础上，添加了测试标识的属性，以保证传输中始终带着测试标识。



##### 2.2.2.2 测试标识覆盖链路诊断

Quake 提供了链路匹配分析的能力，通过平台试探性地发送业务实际需要压测的请求，根据 Mtrace提供的数据，帮助业务快速定位到标记透传失败的服务节点，以避免测试标识就不会再往下进行透传。

 ![1604378873600](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604378873600.png)

![1604378908110](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604378908110.png)

![1604378886574](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604378886574.png)



##### 2.2.2.3 压测服务隔离

根据业务的需求在线上对整条链路快速创建一个压测分组，隔出一批空闲的机器用于压测。将正常流量与测试流量在机器级别进行隔离，从而降低压测对服务集群带来的影响。



![1604379137216](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604379137216.png)

依赖标识透传的机制，在 Quake 平台上提供了基于 IP、机器数、百分比不同方式的隔离策略，业务只需提供所需隔离的服务名，由 Quake 进行一键化的开启与关闭。 



##### 2.2.2.4 压测数据隔离- 脏数据 处理

 **“影子表”隔离方案**：  使用线上同一个数据库，包括共享数据库中的内存资源，因为这样才能更接近真实场景，只是在写入数据时会写在了另一张“影子表”中。 

**MQ** 包括生产和消费两端，业务可以根据实际的需要选择在生产端或者消费端忽略带测试标识的消息。 

##### 2.2.2.4 压测日志隔离

不影响线上日志



### 2.3 调度中心 Quake-Brain

 基于自身的调度算法，调度中心将每个压测任务拆分成若干个可在单台压测引擎上执行的计划，并将计划以指令的方式下发给不同的引擎，从而执行压测任务 

#### 2.3.1 资源计算

 以 HTTP 服务为例，在请求/响应体都在 1K 以内，响应时间在 50ms 以内和 1s 左右的两个请求 。

计算中心会依据压测模型的不同参数，进行资源的计算。主要参考的数据包括：

- 压测期望到达的 QPS。
- 压测请求的平均响应时间和请求/响应体大小。
- 压测的词表大小、分片数。
- 压测类型。
- 所需压测的机房。

#### 2.3.2 事件注入机制

 在整个过程中产生的事件类型包括调整 QPS 的事件、触发熔断的事件、开启事故注入、开启代码级性能分析的事件等等，同时触发事件的情况也有很多种，包括用户手动触发、由于系统保护机制触等等。 

![1604382218830](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604382218830.png)

 在代码设计层面，我们采用了观察者和责任链模式，将会触发事件的具体情况作为观察主题，主题的订阅者会视情况类型产生一连串执行事件。而在执行事件中又引入责任链模式，将各自的处理逻辑进行有效的拆分，以便后期进行维护和能力扩充。 



#### 2.3.3 机器管理

 施压机采用容器化方式进行部署，为后续的动态扩容、施压机灰度升级以及异常摘除的提供了基础保障。 

 **动态扩容** 

 平台也需要事先部署一部分机器用于日常的业务压测。当业务申请资源不足时，平台会按需通过容器化方式动态的进行扩容。 

 **灰度升级** 

对每台施压机提供了版本的概念，机器选择时，优先使用稳定版的机器。根据机器目前使用的状态，分批替换未使用的机器，待新版本的机器跑完基准和回归测试后，将机器选择的策略改为最新版。 

**异常摘除**

调度中心维持了与所有施压机的心跳检测，对于异常节点提供了摘除替换的能力。

#### 2.3.4 压测引擎优化- IO 优化



通常的压测引擎，采用的是 BIO 的方式，利用多线程来模拟并发的用户数，每个线程的工作方式是：请求-等待-响应。  中间的等待过程，线程资源完全被浪费 ， 单机的最大 QPS 就是能创建的最大线程数。  而且线程数控制的粒度太粗，如果请求响应很快，仅几十毫秒，如果增加一个线程，可能 QPS 就上涨了将近100。

我们采用NIO，从客户端发起请求的角度看，存在的 IO 事件分别是建立连接就绪事件（OP_CONNECT）、IO 就绪的可读事件 （OP_READ） 和 IO 就绪的可写事件（OP_WRITE），所有 IO 事件会向事件选择器（Selector）进行注册，并由它进行统一的监听和处理，Selector 这里采用的是 IO 多路复用的方式。 

 整个核心思想就是根据预设的 QPS，保证每秒发出指定数量的请求，再以 IO 非阻塞的方式进行后续的读写操作，取消了 BIO 中请求等待的时间。

优化后的逻辑如下： 

<img src="%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604382825359.png" alt="1604382825359" style="zoom:80%;" />



**优化一：采用 Reactor 多线程模型**

为了达到单位时间内尽可能多的发起压测请求，我们将连接事件与读写事件分离。连接事件采用单线程 Selector 的方式来处理，读写事件分别由多个 Worker 线程处理，每个 Worker 线程也是以 NIO 方式进行处理，由各自的 Selector 处理 IO 事件的读写操作。这里每个 Worker 线程都有自己的事件队列，数据彼此隔离，这样做主要是为了避免数据同步带来的性能开销。

**优化二：业务逻辑与 IO 读写事件分离**

这里说的业务逻辑主要是针对请求结果的处理，包括对请求数据的采样上报，对压测结果的解析校验，对请求转换率的匹配等。如果将这些逻辑放在 Worker 线程中处理，必然会影响 IO 读取的速度。因为 Selector 在监听到 IO 就绪事件后，会进行单线程处理，所以它的处理要尽可能的简单和快速，不然会影响其他就绪事件的处理，甚至造成队列积压和内存问题。

#### 2.3.5 压测引擎优化-内存优化

压测引擎另一个重要的指标是 Full GC 的时间，因为如果引擎频繁出现 Full GC，那会造成实际压测曲线（QPS）的抖动，这种抖动会放大被压服务真实的响应时间，造成真实 QPS 在预设值的上下波动。严重的情况，如果是长时间出现 Full GC，直接就导致预压的 QPS 压不上去的问题。

1、合理分配内存对象

 **请求对象加载机制优化** ， 对于词表数据过大的情况，可以考虑采用流式加载的方式，在队列中维持一定数量的请求，通过边回放边加载的方式来控制内存大小。 

 **请求对象的快用快销**  引擎在实际压测过程中，假设单机是 1W 的 QPS，那它每秒就会创建 1W 个请求对象，这些对象可能在下一秒处理完后就会进行销毁。如果销毁过慢，就会造成大量无效对象晋升老年代，所以在对响应结果的处理中，不要有耗时的操作，保证请求对象的快速释放。 

2、JVM 参数调优

 以 JVM 的 CMS 收集器为例，对于高并发的场景，瞬间产生大量的对象，这些对象的存活时间又非常短 

- 适当增大新生代的大小，保证新生代有足够的空间来容纳新产生的对象。当然如果老年代设置的过小，会导致频繁的 Full GC。
- 适当调大新生代向晋升老年代的存活次数，减少无效对象晋升老年代的机率；同时控制新生代存活区的大小，如果设置的过小，很容易造成那些无法容纳的新生代对象提前晋升。
- 提前触发老年代的 Full GC，因为如果等待老年代满了再开始回收，可能会太晚，这样很容易造成长时间的 Full GC。一般设在 70% 的安全水位进行回收。而且回收的时候，需要触发一次 Young GC，这可以减少重新标记阶段应用暂停的时间，另一方面，也防止在回收结束后，有大量无效的对象进入老年代中。
- 设置需要进行内存压缩整理的 GC 次数，内存整理，很多时候是造成长时间 GC 的主要原因。因为内存整理是采用 Serial Old 算法，以单线程的方式进行处理，这个过程会非常慢。尤其是在老年代空间不足的情况下，GC 的时间会变得更长。

### 2.4 监控模块

监控模块必须提供3级监控【阿里】

![1604384356925](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604384356925.png)

 秒级监控的能力，以及可靠的熔断降级机制 

#### 2.4.1 压测引擎监控

 实时进行处理监控的数据包括各 TP 线的响应情况、QPS 曲线波动、错误率情况以及采样日志分析等等。 

<img src="%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604383348517.png" alt="1604383348517" style="zoom: 80%;" />

QPS

![1604383401912](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604383401912.png)

![1604383423021](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604383423021.png)

#### 2.4.2 服务端监控

 除了通过引擎上报的压测结果来进行相应的监控分析之外，Quake 还集成了公司内部统一的监控组件，有监控机器指标的 Falcon 系统（小米开源），还有监控服务性能的CAT。Quake 提供了统一的管理配置服务，让业务能在 Quake 上方便观察整个系统的健康状况。 



#### 2.4.3 熔断保护机制

Quake 提供了客户端和服务端两方面的熔断保护措施。

首先是客户端熔断，根据业务自定义的熔断阙值，Quake 会实时分析监控数据，当达到熔断阙值时，任务调度器会向压测引擎发送降低 QPS 或者直接中断压测的指令，防止系统被压挂。

 被压服务同样也提供了熔断机制，Quake 集成了公司内部的熔断组件（Rhino），提供了压测过程中的熔断降级和限流能力。 



## 3 项目实施

###  3.1 压测自动化需要解决的关键问题

基础流程如何自动化，提高人效；

如何自动做好压测验证，保障压测安全；

压测置信度量化如何计算，保证压测有效。

![1604385145798](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604385145798.png)

### 3.2 系统总体设计

 ![图3-系统总体逻辑架构](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/6b2c1d36a5c528d3ffc4aeac0f3b5be1271326.png) 

**链路构建/比对**：负责服务接口方法调用链路的构建、更新、存储。

**链路治理**：基于构建的链路关系，提供链路中核心依赖、出口Mock接口等标注、上下游分析、展示，以及出口Mock的配置等功能。

**压测配置管理**：自动发现注册服务的Mafka/Cellar/Squirrel/Zebra的压测配置，辅助压测方核查和配置相关配置项。

**压测验证检查**：确保系统可压测，通过多种校验手段和机制设计，来保证压测的安全性。

**数据构造**：为不同业务压测实施准备基础和流量数据。

**压测计划管理**：设定压测执行计划，并依赖“压测控制”模块，自动调度整个压测执行过程。

**故障诊断**：依据收集的关键业务/服务指标、报警等信息，判断分析服务是否异常，以及是否终止压测。

**置信度评估**：从数据覆盖、链路覆盖、技术指标等维度评估压测结果的置信度，即与真实流量情况下各评估维度的相似性。

**非功能性设计说明** 

可扩展性  能够兼容不同业务线数据构造逻辑的差异性。能够支持不同的流量录制方式。

安全性  集成SSO，按用户所属团队分组，展示所属的压测服务信息。对关键操作留存操作日志。

压测验证检查，是确保压测安全的关键。支持周期性压测验证，能发现待压测服务可压测性随时间的退化。

可重用性  链路构建、事件/指标收集/故障诊断等模块，在稳定性领域是可重用的基础设施，按独立通用模块建设。

### 3.3 链路治理模块设计

![1604385491392](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604385491392.png)

 链路治理模块主要提供链路入口选取、链路标注、服务出口分析、出口Mock配置等功能。

链路关系通过系统自动构建的树结构方式。

![1604386606665](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386606665.png)

 服务出口

 

![1604385725852](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604385725852.png)

![1604385734653](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604385734653.png)

![1604385783049](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604385783049.png)

 在接口调用时，判断是否是压测流量，是的话走Mock逻辑，做模拟时延处理，返回提前配置的响应数据。 

 在实际压测时，平台还可以通过SDK收集Mock逻辑执行的数据，自动与后台标注的Mock数据对比，进行验证。

### 3.4 数据构造模块设计



![1604385940866](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604385940866.png)



 ![1604386002517](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386002517.png)

![1604386011968](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386011968.png)



 数据构造流程，定义了压测基础数据和流量数据生成的整个流程。通过与Quake的交互，获取原始真实的线上数据；构建了一个简版的流程引擎，在统一设定的流程中，如图6所示，通过在标准扩展槽中，配置不同类型的数据构造逻辑和执行顺序，来定义整个数据构造执行的流程；最后，把构造的流量数据与Quake压测场景绑定，作为后续Quake压测施压中，场景回放流量的来源。 

### 3.5 压测验证模块设计

![1604386114424](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386114424.png)

**从待压测服务系统可压测性的角度看**
服务依赖中间件版本要求校验；
Zebra压测配置校验；
Cellar/Squirrel压测配置校验；
Mafka压测开关同步及校验；
服务Mock逻辑存在性校验。

**从压测流量特征的角度看**
MTrace链路标记校验，从压测链路入口出发，收集压测链路信息，校验压测标记信息传递是否符合预期。
服务Mock逻辑压测标记校验，通过增强的校验逻辑，把执行信息上报到平台，与Mock配置时的标注数据对比验证。
压测与真实链路比对校验，利用链路治理模块构建链路的能力，采集压测监控数据重构链路，与真实链路对比验证。

### 3.6 压测计划管理模块设计

![1604386364309](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386364309.png)

 压测计划模块，是整个自动化压测的核心，协同起了各个模块。通过具体的计划任务执行产生的事件，触发了压测验证检查、压测进展播报、收集压测监控/告警等数据，来检测服务是否异常，并根据配置来终止压测，能够故障时及时止损。最后，报告生成模块收到压测终止事件，汇总各种信息，自动生成包括压测基本信息等多维度信息的压测报告，节省了一些压测后分析的时间。 

### 3.7 实际压测过程

#### 1、团队/服务注册

设定实施压测的虚拟团队和压测覆盖范围的应用服务。

#### 2、链路治理

选定压测链路入口，可以得到入口以下的接口链路关系树，便于梳理。明确需要Mock的外部接口，并做配置。

#### 3、应用改造与压测配置

对待接入压测应用改造，满足“服务的可压测条件”
压测应用依赖中间件配置，系统依据构建的链路信息，能够自动发现。提供统一配置和核对的页面功能。

![1604386748242](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386748242.png)

![1604386789508](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386789508.png)

#### 4、Quake准备

 压测自动化系统是基于Quake构建的，流量录制、回放、施压等依赖于此。因此需要到Quake上配置流量录制的“流量任务”和压测执行的“压测场景” 

![1604386899455](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386899455.png)



![1604386931804](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604386931804.png)

#### 5、数据构造

配置数据构造逻辑，当然已有的逻辑都是可复用的单元，可以先查看已有逻辑是否能满足自己的需要。

![1604387006977](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604387006977.png)

 配置数据构造流程 

![1604387064757](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604387064757.png)

#### 6、配置测试计划 

设定压测计划，到启动时间，系统会自动启动压测。

![1604387145264](%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/1604387145264.png)

## 4 项目总结

 1、小步快跑   我们基本平均两周实现一次迭代，然后逐步加入了机器隔离、影子表隔离、数据偏移规则、熔断保护机制、代码级别的性能分析等功能。 

2、快速响应  上线面临问题非常多，不仅有使用层面的问题，系统自身也存在一些 Bug 缺陷。当时，一旦遇到业务线大规模的压测，我们团队都是全员待命，直接在现场解决问题。后续系统稳定后，我们组内采用了客服轮班制度，每个迭代由一位同学专门负责客服工作，保障当业务遇到的问题能够做到快速响应。 

 3、这应该是所有内部项目都会遇到的问题，很多时候，推广成果决定项目的生死。前期我们先在一些比较有代表性的业务线进行试点。如果在试点过程中遇到的问题，或者业务同学提供的一些好的想法和建议，我们能够快速地进行迭代与落地。然后再不断地扩大试点范围，包括美团外卖、猫眼、酒旅、金融等几个大的 BG 都在 Quake 上进行了几轮全流程、大规模的全链路压测。 

开放生态

如果所有事情都依托平台来完成，就会面临做不完的需求，而且很多事情放在平台层面，也可能无解。

同时，Quake 也提供了很多 API 供其他平台进行接入，一些业务高度定制化的工作，就由业务平台独自去完成。

 像 Quake 平台使用的很多监控组件、熔断组件以及性能分析工具，有一些也是兄弟团队刚线上没多久的产品。 

## 5  案例



1、在为一个企业实施生产压测时，偶发性出现用户相应很慢，通过全链路下钻深度分析，发现这些特定的用户访问时，Redis调用非常频繁，当特定用户集中访问时，整个Redis达到容量瓶颈，最终影响到所有用户。 



2、再举一个因开源组件BUG导致的CPU使用暴增引发的故障。在一次压测过程中，我们发现一个服务节点上的某个CPU消耗100%，我们利用平台的深度热点方法分析能力，发现CPU利用率排在第一的方法是通讯框架Netty的内存清理逻辑。经排查，发现是Netty的BUG（高并发下出现死循环），我们本想修复，后发现在其官方4.1.25版本已修复，升级后CPU占满的情况完全消退。最终不仅解决了CPU利用率高的问题，业务的TPS也从2491提升到3040。



https://tech.meituan.com/2019/02/14/full-link-pressure-test-automation.html

